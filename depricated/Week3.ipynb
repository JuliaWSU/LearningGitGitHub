{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[](images/wsu_branding.jpg) \n",
    "<h1 align=\"center\">\n",
    "<img src=\"images/wsu_branding.jpg?raw=1\" width=\"750\" height=\"500\" />\n",
    "</h1>  \n",
    "\n",
    "<!--Russell Jarvis, Postdoctoral researcher [email](r.jarvis@westernsyndney.edu.au)\n",
    "\n",
    "-->\n",
    "The code for this material lives [here](https://github.com/fun-zoological-computing/LearningGitGitHub/blob/master/Week2.ipynb), feel free to hack it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 6001 Neuromorphic Algorithms and Computation \n",
    "\n",
    "# Week 3 - Tutorial 2 â€“ Optimisation Algorithms and Genetic Algorithms \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Elitism versus NSGA \n",
    "\n",
    "* Genes as bitstrings \n",
    "\n",
    "* Elitism select best bubble sort \n",
    "\n",
    "* Mutation and cross over as operations on bitstrings  \n",
    "\n",
    "* Pythons GA DEAP module. Override DEAPS MU and Crossover functions. \n",
    "\n",
    "* Time varying $ \\eta $ (mutation step size). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picture of bitstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deap in /home/user/anaconda3/lib/python3.7/site-packages (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /home/user/anaconda3/lib/python3.7/site-packages (from deap) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "!pip install deap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Genetic Algorithms an \"error function\" is similar to a loss function in regular DEAP learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import logging\n",
    "import deap.algorithms\n",
    "import deap.tools\n",
    "import pickle\n",
    "logger = logging.getLogger('__main__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function deap.benchmarks.zdt1(individual)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deap import benchmarks\n",
    "benchmarks.zdt1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def _evaluate_invalid_fitness(toolbox, population):\n",
    "    '''Evaluate the individuals with an invalid fitness\n",
    "    Returns the count of individuals with invalid fitness\n",
    "    '''\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    return len(invalid_ind)\n",
    "\n",
    "\n",
    "def _update_history_and_hof(halloffame, history, population):\n",
    "    '''Update the hall of fame with the generated individuals\n",
    "    Note: History and Hall-of-Fame behave like dictionaries\n",
    "    '''\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(population)\n",
    "\n",
    "    history.update(population)\n",
    "\n",
    "\n",
    "def _record_stats(stats, logbook, gen, population, invalid_count):\n",
    "    '''Update the statistics with the new population'''\n",
    "    record = stats.compile(population) if stats is not None else {}\n",
    "    logbook.record(gen=gen, nevals=invalid_count, **record)\n",
    "\n",
    "\n",
    "def _get_offspring(parents, toolbox, cxpb, mutpb):\n",
    "    '''return the offsprint, use toolbox.variate if possible'''\n",
    "    if hasattr(toolbox, 'variate'):\n",
    "        return toolbox.variate(parents, toolbox, cxpb, mutpb)\n",
    "    return deap.algorithms.varAnd(parents, toolbox, cxpb, mutpb)\n",
    "\n",
    "\n",
    "def eaAlphaMuPlusLambdaCheckpoint(\n",
    "        population,\n",
    "        toolbox,\n",
    "        mu,\n",
    "        cxpb,\n",
    "        mutpb,\n",
    "        ngen,\n",
    "        stats=None,\n",
    "        halloffame=None,\n",
    "        cp_frequency=1,\n",
    "        cp_filename=None,\n",
    "        continue_cp=False):\n",
    "    r\"\"\"This is the :math:`(~\\alpha,\\mu~,~\\lambda)` evolutionary algorithm\n",
    "    Args:\n",
    "        population(list of deap Individuals)\n",
    "        toolbox(deap Toolbox)\n",
    "        mu(int): Total parent population size of EA\n",
    "        cxpb(float): Crossover probability\n",
    "        mutpb(float): Mutation probability\n",
    "        ngen(int): Total number of generation to run\n",
    "        stats(deap.tools.Statistics): generation of statistics\n",
    "        halloffame(deap.tools.HallOfFame): hall of fame\n",
    "        cp_frequency(int): generations between checkpoints\n",
    "        cp_filename(string): path to checkpoint filename\n",
    "        continue_cp(bool): whether to continue\n",
    "    \"\"\"\n",
    "\n",
    "    if continue_cp:\n",
    "        # A file name has been given, then load the data from the file\n",
    "        cp = pickle.load(open(cp_filename, \"r\"))\n",
    "        population = cp[\"population\"]\n",
    "        parents = cp[\"parents\"]\n",
    "        start_gen = cp[\"generation\"]\n",
    "        halloffame = cp[\"halloffame\"]\n",
    "        logbook = cp[\"logbook\"]\n",
    "        history = cp[\"history\"]\n",
    "        random.setstate(cp[\"rndstate\"])\n",
    "    else:\n",
    "        # Start a new evolution\n",
    "        start_gen = 1\n",
    "        parents = population[:]\n",
    "        logbook = deap.tools.Logbook()\n",
    "        logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "        history = deap.tools.History()\n",
    "\n",
    "        # TODO this first loop should be not be repeated !\n",
    "        invalid_count = _evaluate_invalid_fitness(toolbox, population)\n",
    "        _update_history_and_hof(halloffame, history, population)\n",
    "        _record_stats(stats, logbook, start_gen, population, invalid_count)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(start_gen + 1, ngen + 1):\n",
    "        offspring = _get_offspring(parents, toolbox, cxpb, mutpb)\n",
    "\n",
    "        population = parents + offspring\n",
    "\n",
    "        invalid_count = _evaluate_invalid_fitness(toolbox, offspring)\n",
    "        _update_history_and_hof(halloffame, history, population)\n",
    "        _record_stats(stats, logbook, gen, population, invalid_count)\n",
    "\n",
    "        # Select the next generation parents\n",
    "        parents = toolbox.select(population, mu)\n",
    "\n",
    "        logger.info(logbook.stream)\n",
    "\n",
    "        if(cp_filename and cp_frequency and\n",
    "           gen % cp_frequency == 0):\n",
    "            cp = dict(population=population,\n",
    "                      generation=gen,\n",
    "                      parents=parents,\n",
    "                      halloffame=halloffame,\n",
    "                      history=history,\n",
    "                      logbook=logbook,\n",
    "                      rndstate=random.getstate())\n",
    "            pickle.dump(cp, open(cp_filename, \"wb\"))\n",
    "            logger.debug('Wrote checkpoint to %s', cp_filename)\n",
    "\n",
    "    return population, logbook, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import logging\n",
    "import functools\n",
    "import numpy\n",
    "\n",
    "import deap\n",
    "import deap.base\n",
    "import deap.algorithms\n",
    "import deap.tools\n",
    "\n",
    "\n",
    "class WeightedSumFitness(deap.base.Fitness):\n",
    "\n",
    "    \"\"\"Fitness that compares by weighted sum\"\"\"\n",
    "\n",
    "    def __init__(self, values=(), obj_size=None):\n",
    "        self.weights = [-1.0] * obj_size if obj_size is not None else [-1]\n",
    "\n",
    "        super(WeightedSumFitness, self).__init__(values)\n",
    "\n",
    "    @property\n",
    "    def weighted_sum(self):\n",
    "        \"\"\"Weighted sum of wvalues\"\"\"\n",
    "        return sum(self.wvalues)\n",
    "\n",
    "    @property\n",
    "    def sum(self):\n",
    "        \"\"\"Weighted sum of values\"\"\"\n",
    "        return sum(self.values)\n",
    "\n",
    "    @property\n",
    "    def norm(self):\n",
    "        \"\"\"Frobenius norm of values\"\"\"\n",
    "        return numpy.linalg.norm(self.values)\n",
    "\n",
    "    def __le__(self, other):\n",
    "        return self.weighted_sum <= other.weighted_sum\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.weighted_sum < other.weighted_sum\n",
    "\n",
    "    def __deepcopy__(self, _):\n",
    "        \"\"\"Override deepcopy\"\"\"\n",
    "\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "        result.__dict__.update(self.__dict__)\n",
    "        return result\n",
    "\n",
    "\n",
    "class WSListIndividual(list):\n",
    "\n",
    "    \"\"\"Individual consisting of list with weighted sum field\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.rheobase = None\n",
    "        self.fitness = WeightedSumFitness(obj_size=kwargs['obj_size'])\n",
    "        del kwargs['obj_size']\n",
    "        super(WSListIndividual, self).__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "class DEAPOptimisation():\n",
    "\n",
    "    \"\"\"DEAP Optimisation class\"\"\"\n",
    "\n",
    "    def get_trans_list(self,param_dict):\n",
    "        trans_list = []\n",
    "        for i,k in enumerate([param_dict.keys()]):\n",
    "            trans_list.append(k)\n",
    "        return trans_list\n",
    "\n",
    "    def setnparams(self, nparams = 10, provided_dict = None):\n",
    "        self.params = optimization_management.create_subset(nparams = nparams,provided_dict = provided_dict)\n",
    "        self.nparams = len(self.params)\n",
    "        self.td = self.get_trans_list(self.params)\n",
    "        return self.params, self.td\n",
    "\n",
    "\n",
    "    def __init__(self, error_criterion = None, evaluator = None,\n",
    "                 selection = 'selIBEA',\n",
    "                 benchmark = False,\n",
    "                 seed=1,\n",
    "                 offspring_size=15,\n",
    "                 elite_size=0,\n",
    "                 eta=10,\n",
    "                 mutpb=1.0,\n",
    "                 cxpb=1.0,\n",
    "                 map_function=None,\n",
    "                 backend=None,\n",
    "                 nparams = 10,\n",
    "                 provided_dict= {}):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "\n",
    "        super(DEAPOptimisation, self).__init__()\n",
    "        self.selection = selection\n",
    "        self.benchmark = benchmark\n",
    "        self.error_criterion = error_criterion\n",
    "        self.seed = seed\n",
    "        self.offspring_size = offspring_size\n",
    "        self.elite_size = elite_size\n",
    "        self.eta = eta\n",
    "        self.cxpb = cxpb\n",
    "        self.mutpb = mutpb\n",
    "        #self.CPU_NUM = CPU_NUM\n",
    "        self.backend = backend\n",
    "        # Create a DEAP toolbox\n",
    "        self.toolbox = deap.base.Toolbox()\n",
    "        self.setnparams(nparams = nparams, provided_dict = provided_dict)\n",
    "        self.setup_deap()\n",
    "\n",
    "\n",
    "\n",
    "    def set_evaluate(self):\n",
    "        self.toolbox.register(\"evaluate\", benchmarks.zdt1)\n",
    "        \n",
    "    def setup_deap(self):\n",
    "        \"\"\"Set up optimisation\"\"\"\n",
    "\n",
    "        # Number of objectives\n",
    "        #OBJ_SIZE = len(self.evaluator.objectives)\n",
    "\n",
    "        # Set random seed\n",
    "        random.seed(self.seed)\n",
    "\n",
    "        # Eta parameter of crossover / mutation parameters\n",
    "        # Basically defines how much they 'spread' solution around\n",
    "        # The lower this value, the more spread\n",
    "        ETA = self.eta\n",
    "\n",
    "        # Number of parameters\n",
    "        # Bounds for the parameters\n",
    "        IND_SIZE = len(list(self.params.values()))\n",
    "        OBJ_SIZE = len(self.error_criterion)\n",
    "        import numpy as np\n",
    "        LOWER = [ np.min(self.params[v]) for v in self.td ]\n",
    "        UPPER = [ np.max(self.params[v]) for v in self.td ]\n",
    "        if self.backend == 'glif':\n",
    "            for index, i in enumerate(UPPER):\n",
    "                if i == LOWER[index]:\n",
    "                    LOWER[index]-=2.0\n",
    "                    i+=2.0\n",
    "\n",
    "        # import pdb; pdb.set_trace()\n",
    "        # Define a function that will uniformly pick an individual\n",
    "        def uniform(lower_list, upper_list, dimensions):\n",
    "            \"\"\"Fill array \"\"\"\n",
    "\n",
    "            if hasattr(lower_list, '__iter__'):\n",
    "                return [random.uniform(lower, upper) for lower, upper in\n",
    "                        zip(lower_list, upper_list)]\n",
    "            else:\n",
    "                return [random.uniform(lower_list, upper_list)\n",
    "                        for _ in range(dimensions)]\n",
    "\n",
    "        # Register the 'uniform' function\n",
    "        self.toolbox.register(\"uniformparams\", uniform, LOWER, UPPER, IND_SIZE)\n",
    "\n",
    "        # Register the individual format\n",
    "        # An indiviual is create by WSListIndividual and parameters\n",
    "        # are initially\n",
    "        # picked by 'uniform'\n",
    "        self.toolbox.register(\n",
    "            \"Individual\",\n",
    "            deap.tools.initIterate,\n",
    "            functools.partial(WSListIndividual, obj_size=OBJ_SIZE),\n",
    "            self.toolbox.uniformparams)\n",
    "\n",
    "        # Register the population format. It is a list of individuals\n",
    "        self.toolbox.register(\n",
    "            \"population\",\n",
    "            deap.tools.initRepeat,\n",
    "            list,\n",
    "            self.toolbox.Individual)\n",
    "\n",
    "        # Register the evaluation function for the individuals\n",
    "        def custom_code(invalid_ind):\n",
    "            if self.backend is None:\n",
    "                invalid_pop = list(update_deap_pop(invalid_ind, self.error_criterion, td = self.td))\n",
    "            else:\n",
    "                invalid_pop = list(update_deap_pop(invalid_ind, self.error_criterion, td = self.td, backend = self.backend))\n",
    "            assert len(invalid_pop) != 0\n",
    "            invalid_dtc = [ i.dtc for i in invalid_pop if hasattr(i,'dtc') ]\n",
    "            fitnesses = list(map(evaluate, invalid_dtc))\n",
    "            return fitnesses\n",
    "\n",
    "        self.toolbox.register(\"evaluate\", custom_code)\n",
    "        # Register the mate operator\n",
    "        self.toolbox.register(\n",
    "            \"mate\",\n",
    "            deap.tools.cxSimulatedBinaryBounded,\n",
    "            eta=ETA,\n",
    "            low=LOWER,\n",
    "            up=UPPER)\n",
    "\n",
    "        # Register the mutation operator\n",
    "        self.toolbox.register(\n",
    "            \"mutate\",\n",
    "            deap.tools.mutPolynomialBounded,\n",
    "            eta=ETA,\n",
    "            low=LOWER,\n",
    "            up=UPPER,\n",
    "            indpb=0.5)\n",
    "\n",
    "        # Register the variate operator\n",
    "        self.toolbox.register(\"variate\", deap.algorithms.varAnd)\n",
    "        self.toolbox.register(\"select\", tools.selIBEA)\n",
    "        '''\n",
    "        # Register the selector (picks parents from population)\n",
    "        if self.selection == str('ngsa'):\n",
    "            self.toolbox.register(\"select\", tools.selNSGA2)\n",
    "        elif\n",
    "        self.selection == str('selIBEA'):\n",
    "        '''\n",
    "    def run(self,\n",
    "            max_ngen=25,\n",
    "            offspring_size=None,\n",
    "            continue_cp=False,\n",
    "            cp_filename=None,\n",
    "            cp_frequency=0):\n",
    "        \"\"\"Run optimisation\"\"\"\n",
    "        # Allow run function to override offspring_size\n",
    "        # TODO probably in the future this should not be an object field anymore\n",
    "        # keeping for backward compatibility\n",
    "        if offspring_size is None:\n",
    "            offspring_size = self.offspring_size\n",
    "\n",
    "        # Generate the population object\n",
    "        pop = self.toolbox.population(n=offspring_size)\n",
    "        hof = deap.tools.HallOfFame(offspring_size)\n",
    "\n",
    "\n",
    "        stats = deap.tools.Statistics(key=lambda ind: ind.fitness.sum)\n",
    "        stats.register(\"avg\", numpy.mean)\n",
    "        stats.register(\"std\", numpy.std)\n",
    "        stats.register(\"min\", numpy.min)\n",
    "        stats.register(\"max\", numpy.max)\n",
    "\n",
    "        pop, log, history, gen_vs_hof = algorithms.eaAlphaMuPlusLambdaCheckpoint(\n",
    "            pop,\n",
    "            self.toolbox,\n",
    "            offspring_size,\n",
    "            self.cxpb,\n",
    "            self.mutpb,\n",
    "            max_ngen,\n",
    "            stats=stats,\n",
    "            halloffame=hof,\n",
    "            nelite=self.elite_size,\n",
    "            cp_frequency=cp_frequency,\n",
    "            continue_cp=continue_cp,\n",
    "            cp_filename=cp_filename,\n",
    "            selection = self.selection,\n",
    "            td = self.td)\n",
    "\n",
    "        # insert the initial HOF value back in.\n",
    "\n",
    "        td = self.td\n",
    "        return pop, hof, log, history, td, gen_vs_hof\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
