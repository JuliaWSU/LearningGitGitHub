{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "[](images/wsu_branding.jpg) \n",
    "<h1 align=\"center\">\n",
    "<img src=\"images/wsu_branding.jpg?raw=1\" width=\"750\" height=\"500\" />\n",
    "</h1>  \n",
    "\n",
    "<!--Russell Jarvis, Postdoctoral researcher [email](r.jarvis@westernsyndney.edu.au)\n",
    "\n",
    "-->\n",
    "The code for this material lives [here](https://github.com/fun-zoological-computing/LearningGitGitHub/blob/master/Week2.ipynb), feel free to hack it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 6001 Neuromorphic Algorithms and Computation\n",
    "\n",
    "## Assignment 2 – Event Generation (30%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Background: \n",
    "* Frame to event conversion is a technique mostly used to understand the principles of neuromorphic imaging  \n",
    "\n",
    "* “What I cannot create, I do not understand.” Richard Feynman\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the provided dataset is a greyscale video sequence. The aim of this task is to produce an event stream (x, y, p, t), of the recording.\n",
    "\n",
    "# Q1.\n",
    "Build an algorithm to convert the video sequence to an event stream with a reasonable SNR and high temporal resolution  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Q2. \n",
    "(15%) Evaluate and briefly justify your algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Marking\n",
    "\n",
    "* Justification of algorithm choice (7.5/15)\n",
    "\n",
    "* Complexity (2.5/15)\n",
    "\n",
    "* Scalability (2.5/15)\n",
    "\n",
    "* Similarity to solutions within literature (2.5/15)\n",
    "\n",
    "* Profiling to identify bottlenecks (2.5/15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission requirements:\n",
    "\n",
    "All code must be written using Jupyter Notebooks, or Matlab Live Script  \n",
    "\n",
    "Written components will need be written in a markup or similar format within the Notebook/Live Script\n",
    "\n",
    "Submission is via GIT Classroom, and Turnitin. Copy the code as plain text to a document and submit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
