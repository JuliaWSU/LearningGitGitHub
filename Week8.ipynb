{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d003017",
   "metadata": {},
   "source": [
    "# COMP 6001 Neuromorphic Algorithms and Computation \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3731fc8",
   "metadata": {},
   "source": [
    "## Week 8 - Tutorial 6 – ML and Feature Extraction \n",
    "### Q1. \n",
    "\n",
    "Many popular ML methods used for feature extraction in neuromorphic vision data involve networks with similarities to \n",
    "Self-Organising Maps, particularly algorithms such as FEAST and HOTS. At their core, these feature extraction algorithms work to\n",
    "cluster event contexts (a neighbourhood surrounding the most recent event). When an event is received, the neuron which the \n",
    "incoming event context most closely resembles ‘spikes’. In a winner-take-all style approach, the spiking neuron weight is \n",
    "updated/mixed with the event context (as a function of the learning rate) to gradually learn the common features. \n",
    "Implement a basic neuron-based feature extraction algorithm with this approach. The algorithm should: \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e21af6",
   "metadata": {},
   "source": [
    "\n",
    "* Initialise 9 random 11x11 weights \n",
    "* Hint numpy.random.rand\n",
    "\n",
    "Create a time surface of the incoming event stream \n",
    "Extract the event context from the time surface (with the same dimensions as the weights) \n",
    "Check which neuron is the most similar (cosine distance) \n",
    "Update the neuron weight \n",
    "\n",
    "```python\n",
    "weights = np.random.rand(11,11)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37727414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "!pip install line_profiler --quiet;\n",
    "!pip install memory_profiler --quiet;\n",
    "!pip install black --quiet;\n",
    "# jupyter nbextension install https://github.com/drillan/jupyter-black/archive/master.zip --user\n",
    "%load_ext nbextension enable jupyter-black-master/jupyter-black\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90204b7",
   "metadata": {},
   "source": [
    "Repeat \n",
    "### Q2. \n",
    "Profile and evaluate this system, how scalable is it? What are the most costly components of the algorithm? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f239a",
   "metadata": {},
   "source": [
    "### Q3. \n",
    "What alternate approaches can be used here? What update/learning calculation or similarity metric could be more beneficial? \n",
    "\n",
    "Example FEAST Network neurons extracting and clustering features from the EBC Plane Dropping dataset (Afshar, S., Ralph, N., Xu, Y., Tapson, J., Schaik, A.V. and Cohen, G., 2020. Event-based feature extraction using adaptive selection thresholds. Sensors, 20(6), p.1600.) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee4ed34",
   "metadata": {},
   "source": [
    "\"We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.\"\n",
    "\n",
    "But once you have your code working, it can be useful to dig into its efficiency a bit. \n",
    "Sometimes it's useful to check the execution time of a given command or set of commands; other times it's \n",
    "useful to dig into a multiline process and determine where the bottleneck lies in some complicated series of operations.\n",
    "IPython provides access to a wide array of functionality for this kind of timing and profiling of code. \n",
    "Here we'll discuss the following IPython magic commands:\n",
    "\n",
    "```\n",
    "%time: Time the execution of a single statement\n",
    "%timeit: Time repeated execution of a single statement for more accuracy\n",
    "%prun: Run code with the profiler\n",
    "%lprun: Run code with the line-by-line profiler\n",
    "%memit: Measure the memory use of a single statement\n",
    "%mprun: Run code with the line-by-line memory profiler\n",
    "```\n",
    "The last four commands are not bundled with IPython–you'll need to get the line_profiler and memory_profiler extensions, which we will discuss in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simulation.py\n",
    "import numpy as np\n",
    "\n",
    "def step(*shape):\n",
    "    # Create a random n-vector with +1 or -1 values.\n",
    "    return 2 * (np.random.random_sample(shape)<.5) - 1\n",
    "\n",
    "def simulate(iterations, n=10000):\n",
    "    s = step(iterations, n)\n",
    "    x = np.cumsum(s, axis=0)\n",
    "    bins = np.arange(-30, 30, 1)\n",
    "    y = np.vstack([np.histogram(x[i,:], bins)[0]\n",
    "                   for i in range(iterations)])\n",
    "    return y\n",
    "#3.  Now, let's import this script into the interactive namespace so that we can execute and profile our code:\n",
    "\n",
    "from simulation import simulate\n",
    "#4.  We execute the function under the control of the line profiler. The functions to be profiled need to be explicitly specified in the %lprun magic command. We also save the report in a file named lprof0:\n",
    "\n",
    "%lprun -T lprof0 -f simulate simulate(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94009b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mprun -T lprof0 -f simulate simulate(50)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
